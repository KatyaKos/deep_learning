{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAFSAEDVLKEYDRRRRMEALLLSLYYPNDRKLLDYKEWSPPRVQV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSIIGATRLQNDKSDTYSAGPCYAGGCSAFTPRGTCGKDWDLGEQT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MQNPLPEVMSPEHDKRTTTPMSKEANKFIRELDKKPGDLAVVSDFV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDSLNEVCYEQIKGTFYKGLFGDFPLIVDKKTGCFNATKLCVLGGK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEAKNITIDNTTYNFFKFYNINQPLTNLKYLNSERLCFSNAVMGKI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sequences\n",
       "0  MAFSAEDVLKEYDRRRRMEALLLSLYYPNDRKLLDYKEWSPPRVQV...\n",
       "1  MSIIGATRLQNDKSDTYSAGPCYAGGCSAFTPRGTCGKDWDLGEQT...\n",
       "2  MQNPLPEVMSPEHDKRTTTPMSKEANKFIRELDKKPGDLAVVSDFV...\n",
       "3  MDSLNEVCYEQIKGTFYKGLFGDFPLIVDKKTGCFNATKLCVLGGK...\n",
       "4  MEAKNITIDNTTYNFFKFYNINQPLTNLKYLNSERLCFSNAVMGKI..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df = pd.read_table('data/family_classification_sequences.tab')\n",
    "seq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodoneTransformer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.len = ord('Z') - ord('A') + 1\n",
    "        self.codones = {}\n",
    "        \n",
    "    def set_codones_dict(self, dict_copy):\n",
    "        self.codones = dict_copy.copy()\n",
    "    \n",
    "    def to_int(self, codone):\n",
    "        res = 0\n",
    "        for i in range(3):\n",
    "            res += (ord(codone[i]) - ord('A')) * (self.len ** i)\n",
    "        self.codones[res] = codone\n",
    "        return res\n",
    "    \n",
    "    def to_codone(self, intt):\n",
    "        assert(intt in self.codones)\n",
    "        return self.codones[intt]\n",
    "\n",
    "codone_transformer = CodoneTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_codones(sseq):\n",
    "    crop = len(sseq) % 3\n",
    "    cropped_seq = sseq[:-crop] if crop > 0 else sseq\n",
    "\n",
    "    return [codone_transformer.to_int(cropped_seq[i:i+3]) for i in range(0, len(cropped_seq), 3)]\n",
    "\n",
    "def seq_to3(seq):\n",
    "    splittings = [make_codones(seq[i:]) for i in range(3)]\n",
    "    return splittings\n",
    "\n",
    "def create_all_codones(df):\n",
    "    codones = []\n",
    "\n",
    "    for i in range(7000):\n",
    "        row = df.iloc[i, :][0]\n",
    "        codones.extend(seq_to3(row))\n",
    "    return codones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_or_create(read_path, producer):\n",
    "    if os.path.isfile(read_path):\n",
    "        print('reading', read_path)\n",
    "        with open(read_path, 'rb') as fp:\n",
    "            return pickle.load(fp)\n",
    "    result = producer()\n",
    "    print('saving', read_path)\n",
    "    with open(read_path, 'wb') as fp:\n",
    "        pickle.dump(result, fp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data/all_codones.pickle\n",
      "reading data/codones_to_int.pickle\n"
     ]
    }
   ],
   "source": [
    "all_codones = read_or_create(read_path='data/all_codones.pickle',\n",
    "                             producer= lambda: create_all_codones(seq_df))\n",
    "codone_transformer.set_codones_dict(read_or_create(read_path='data/codones_to_int.pickle',\n",
    "                                                  producer= lambda: codone_transformer.codones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(index_words_list, context_window_size):\n",
    "    \"\"\" Form training pairs according to the skip-gram model. \"\"\"\n",
    "    for index_words in index_words_list:\n",
    "        for index, center in enumerate(index_words):\n",
    "            context = random.randint(1, context_window_size)\n",
    "            # get a random target before the center word\n",
    "            for target in index_words[max(0, index - context): index]:\n",
    "                yield center, target\n",
    "            # get a random target after the center wrod\n",
    "            for target in index_words[index + 1: index + context + 1]:\n",
    "                yield center, target\n",
    "\n",
    "\n",
    "def get_batch(iterator, batch_size):\n",
    "    \"\"\" Group a numerical stream into batches and yield them as Numpy arrays. \"\"\"\n",
    "    while True:\n",
    "        center_batch = np.zeros(batch_size, dtype=np.int32)\n",
    "        target_batch = np.zeros([batch_size, 1], dtype=np.int32)\n",
    "        for index in range(batch_size):\n",
    "            center_batch[index], target_batch[index] = next(iterator)\n",
    "        yield center_batch, target_batch\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    return [item for sublist in x for item in sublist]\n",
    "\n",
    "\n",
    "def cod_to_dict(cod, dictionary):\n",
    "    return [dictionary[key] for key in cod]\n",
    "\n",
    "def make_dictionary(all_codones):\n",
    "    flat_codones = flatten(all_codones)\n",
    "    unique_codones = set(flat_codones)\n",
    "    dictionary = {cod: i for i, cod in enumerate(unique_codones)}\n",
    "    return dictionary\n",
    "\n",
    "def process_data(all_codones, dictionary, batch_size, skip_window):\n",
    "    cod_dicts = [cod_to_dict(cod, dictionary) for cod in all_codones]\n",
    "    single_gen = generate_sample(cod_dicts, context_window_size=skip_window)\n",
    "    batch_gen = get_batch(single_gen, batch_size=batch_size)\n",
    "    return batch_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = make_dictionary(all_codones)\n",
    "count = [0] * len(dictionary)\n",
    "new_codones = flatten(all_codones)\n",
    "for codone in new_codones:\n",
    "    count[dictionary[codone]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SKIP_WINDOW = 12  # the context window\n",
    "VOCAB_SIZE = len(dictionary)\n",
    "EMBED_SIZE = 100  # dimension of the word embedding vectors\n",
    "NUM_SAMPLED = 5  # Number of negative examples to sample.\n",
    "LEARNING_RATE = .02\n",
    "NUM_TRAIN_STEPS = 200000\n",
    "SKIP_STEP = 1000\n",
    "\n",
    "batch_gen = process_data(all_codones, dictionary, BATCH_SIZE, SKIP_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.u = nn.Embedding(vocab_size, embed_size)\n",
    "        self.v = nn.Embedding(vocab_size, embed_size)\n",
    "        self.u.weight.data.uniform_(-0.5 / embed_size, 0.5 / embed_size)\n",
    "        self.v.weight.data.uniform_(-0, 0)\n",
    "                  \n",
    "    def forward(self, u_pos, v_pos, v_neg):\n",
    "        u = self.u(u_pos)\n",
    "        v = self.v(v_pos)\n",
    "        res = 0.0\n",
    "        \n",
    "        score = torch.mul(u, v).squeeze().sum(dim=1)\n",
    "        res += F.logsigmoid(score).sum()\n",
    "        \n",
    "        v = self.v(v_neg)\n",
    "        score = torch.bmm(v, u.unsqueeze(2)).squeeze()\n",
    "        res += F.logsigmoid(-score).sum()\n",
    "        return -res / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "    total_loss = 0.0\n",
    "    threshold = 13.5 * SKIP_STEP\n",
    "    for step in range(NUM_TRAIN_STEPS):\n",
    "        u, v = next(batch_gen)\n",
    "        v_neg = np.random.choice(VOCAB_SIZE, size=(BATCH_SIZE, NUM_SAMPLED))\n",
    "        u = torch.tensor(u, dtype=torch.long)\n",
    "        v = torch.tensor(v, dtype=torch.long)\n",
    "        v_neg = torch.tensor(v_neg, dtype=torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = model.forward(u, v, v_neg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if step % SKIP_STEP == 0 and step > 0:\n",
    "            print('Average loss on step %d is %.3f' % (step, total_loss / SKIP_STEP))\n",
    "            if total_loss <= threshold:\n",
    "                break  # Because it's too long to wait and it probably won't get smaller\n",
    "            total_loss = 0.0\n",
    "\n",
    "    return model.u.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data/embeddings.pickle\n"
     ]
    }
   ],
   "source": [
    "model = SkipGramModel(VOCAB_SIZE, EMBED_SIZE)\n",
    "final_embed_matrix = read_or_create(read_path='data/embeddings.pickle',\n",
    "                                    producer=lambda: train_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "XX = tsne.fit_transform(final_embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>codone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.844692</td>\n",
       "      <td>51.136932</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.412998</td>\n",
       "      <td>-39.041664</td>\n",
       "      <td>CAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.300194</td>\n",
       "      <td>39.153183</td>\n",
       "      <td>DAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.061016</td>\n",
       "      <td>42.883232</td>\n",
       "      <td>EAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-23.295715</td>\n",
       "      <td>42.688427</td>\n",
       "      <td>FAA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x0         x1 codone\n",
       "0  47.844692  51.136932    AAA\n",
       "1  42.412998 -39.041664    CAA\n",
       "2  66.300194  39.153183    DAA\n",
       "3  59.061016  42.883232    EAA\n",
       "4 -23.295715  42.688427    FAA"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_df = pd.DataFrame(XX, columns=['x0', 'x1'])\n",
    "unique_codones_ints = sorted(dictionary, key=dictionary.get)\n",
    "unique_codones = []\n",
    "for intt in list(unique_codones_ints):\n",
    "    unique_codones.append(codone_transformer.to_codone(intt))    \n",
    "tsne_df['codone'] = list(unique_codones)\n",
    "tsne_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_df(df):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.title('unlabeled encoding', fontsize=20)\n",
    "    plt.scatter(df.x0, df.x1, s=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne_df(tsne_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/acid_properties.csv'\n",
    "props = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acid_dict(some_c, props):\n",
    "    prop_by_letter = [props[props.acid == let].iloc[:, 1:] for let in some_c]   \n",
    "    df_concat = pd.concat(prop_by_letter)\n",
    "    res = df_concat.mean()\n",
    "    dres = dict(res)\n",
    "    dres['acid'] = some_c\n",
    "    return dres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data/all_acid_dicts.pickle\n"
     ]
    }
   ],
   "source": [
    "save_path = 'data/all_acid_dicts.pickle'\n",
    "producer = lambda: [acid_dict(some_c, props) for some_c in tsne_df.codone]\n",
    "all_acid_dicts = read_or_create(save_path, producer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acid</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>mass</th>\n",
       "      <th>number_of_atoms</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>71.077900</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>88.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAA</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>81.766233</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>95.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAA</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>85.747733</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>96.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAA</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>90.423267</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>105.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAA</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>96.443233</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>122.366667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acid  hydrophobicity       mass  number_of_atoms      volume\n",
       "0  AAA        1.800000  71.077900        13.000000   88.600000\n",
       "1  CAA        2.033333  81.766233        13.333333   95.233333\n",
       "2  DAA        0.033333  85.747733        14.000000   96.100000\n",
       "3  EAA        0.033333  90.423267        15.000000  105.200000\n",
       "4  FAA        2.133333  96.443233        16.333333  122.366667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acid_df = pd.DataFrame(all_acid_dicts)\n",
    "all_acid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acid</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>mass</th>\n",
       "      <th>number_of_atoms</th>\n",
       "      <th>volume</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>71.077900</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>88.600000</td>\n",
       "      <td>47.844692</td>\n",
       "      <td>51.136932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAA</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>81.766233</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>95.233333</td>\n",
       "      <td>42.412998</td>\n",
       "      <td>-39.041664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAA</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>85.747733</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>96.100000</td>\n",
       "      <td>66.300194</td>\n",
       "      <td>39.153183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAA</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>90.423267</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>105.200000</td>\n",
       "      <td>59.061016</td>\n",
       "      <td>42.883232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAA</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>96.443233</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>122.366667</td>\n",
       "      <td>-23.295715</td>\n",
       "      <td>42.688427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acid  hydrophobicity       mass  number_of_atoms      volume         x0  \\\n",
       "0  AAA        1.800000  71.077900        13.000000   88.600000  47.844692   \n",
       "1  CAA        2.033333  81.766233        13.333333   95.233333  42.412998   \n",
       "2  DAA        0.033333  85.747733        14.000000   96.100000  66.300194   \n",
       "3  EAA        0.033333  90.423267        15.000000  105.200000  59.061016   \n",
       "4  FAA        2.133333  96.443233        16.333333  122.366667 -23.295715   \n",
       "\n",
       "          x1  \n",
       "0  51.136932  \n",
       "1 -39.041664  \n",
       "2  39.153183  \n",
       "3  42.883232  \n",
       "4  42.688427  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = all_acid_df.join(tsne_df.set_index('codone'), on='acid')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_properties(final_df):\n",
    "    plt.figure(figsize=(25, 20))\n",
    "    for i, p in enumerate(['hydrophobicity', 'mass', 'number_of_atoms', 'volume']):\n",
    "        plt.subplot(2,2,i+1)\n",
    "        plt.title(p, fontsize=25)\n",
    "        plt.scatter(final_df.x0, final_df.x1, c=final_df[p], s=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding_properties(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/nice_embed_tsne.csv'\n",
    "gensim_tsne_df = pd.read_csv(filename, index_col=0)\n",
    "gensim_tsne_df.columns = ['x0', 'x1', 'codone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne_df(gensim_tsne_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_nice = all_acid_df.join(gensim_tsne_df.set_index('codone'), on='acid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding_properties(final_df_nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
