{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from IPython import display\n",
    "from sklearn import datasets, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y) = datasets.make_circles(n_samples=1024, shuffle=True, noise=0.2, factor=0.4)\n",
    "ind = (y==1) | (X[:,1] > X[:,0] - 0.5)\n",
    "\n",
    "X = X[ind,:]\n",
    "X = preprocessing.scale(X)\n",
    "y = y[ind]\n",
    "y = 2*y - 1\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='black')\n",
    "plt.show()\n",
    "\n",
    "X, y = torch.FloatTensor(X), torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "h = 0.01\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "def visualize(X, y, w, loss, n_iter):    \n",
    "    plt.clf()\n",
    "    xy = torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = classify(xy, w)\n",
    "    \n",
    "    Z = Z.numpy()\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='black')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(loss)\n",
    "    plt.grid()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.ylim(0, ymax)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(X):\n",
    "    prod = X[:,0] * X[:,1]\n",
    "    prod = prod.unsqueeze(1)\n",
    "    oness = torch.ones_like(X[:, 0])\n",
    "    oness = oness.unsqueeze(1)\n",
    "    res = torch.cat([X, X ** 2, prod, oness], dim=1)\n",
    "    return torch.FloatTensor(res)\n",
    "\n",
    "def classify(X, w):\n",
    "    return expand(X).mv(w).sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(x, y, w):\n",
    "    l = y * xx.mv(w)\n",
    "    return torch.ones_like(l) - l\n",
    "\n",
    "def compute_loss(X, y, w):\n",
    "    xx = expand(X)\n",
    "    l = y * xx.mv(w)\n",
    "    delta = torch.ones_like(l) - l\n",
    "    return delta.max(torch.zeros_like(delta)).mean()\n",
    "\n",
    "def compute_grad(X, y, w):\n",
    "    xx = expand(X)\n",
    "    xt = xx.t()\n",
    "    delta = get_delta(xx, y, w)\n",
    "    return torch.where(delta > 0, -xt * y, torch.zeros_like(xt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "w = torch.Tensor([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "n_iter = 50\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(n_iter):\n",
    "    ind = random.sample(range(X.shape[0]), batch_size)\n",
    "    loss[i] = compute_loss(X, y, w)\n",
    "    visualize(X[ind,:], y[ind], w, loss, n_iter)\n",
    "    \n",
    "    w = w - alpha * compute_grad(X[ind,:], y[ind], w)\n",
    "\n",
    "print(w.shape)\n",
    "visualize(X, y, w, loss, n_iter)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient with momentum\n",
    "\n",
    "w = torch.Tensor([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "alpha =  1 # ?!\n",
    "mu    =  1 # ?!\n",
    "\n",
    "v = torch.zeros_like(w)\n",
    "\n",
    "n_iter = 50\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(n_iter):\n",
    "    ind = random.sample(range(X.shape[0]), batch_size)\n",
    "    loss[i] = compute_loss(X, y, w)\n",
    "    visualize(X[ind,:], y[ind], w, loss, n_iter)\n",
    "    \n",
    "    v = mu * v - alpha * compute_grad(X[ind,:], y[ind], w)\n",
    "    w += v\n",
    "\n",
    "visualize(X, y, w, loss, n_iter)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesterov\n",
    "\n",
    "w = torch.Tensor([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "alpha = 1 # ?!\n",
    "mu    = 1 # ?!\n",
    "\n",
    "v = torch.zeros_like(w)\n",
    "\n",
    "n_iter = 50\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(n_iter):\n",
    "    ind = random.sample(range(X.shape[0]), batch_size)\n",
    "    loss[i] = compute_loss(X, y, w)\n",
    "    visualize(X[ind,:], y[ind], w, loss, n_iter)\n",
    "    \n",
    "    v = mu * v - alpha * compute_grad(X[ind,:], y[ind], w + mu * v)\n",
    "    w += v\n",
    "\n",
    "visualize(X, y, w, loss, n_iter)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam\n",
    "\n",
    "w = torch.Tensor([1, 0, 0, 0, 0, 0])\n",
    "\n",
    "alpha = 1 # ?!\n",
    "beta = 0.9 # ?!\n",
    "mu = 0.999 # ?!\n",
    "eps = 0.01 # ?!\n",
    "\n",
    "v = torch.zeros_like(w)\n",
    "g = torch.zeros_like(w)\n",
    "\n",
    "\n",
    "n_iter = 50\n",
    "batch_size = 4\n",
    "loss = np.zeros(n_iter)\n",
    "plt.figure(figsize=(12,5))\n",
    "for i in range(n_iter):\n",
    "    ind = random.sample(range(X.shape[0]), batch_size)\n",
    "    loss[i] = compute_loss(X, y, w)\n",
    "    visualize(X[ind,:], y[ind], w, loss, n_iter)\n",
    "    \n",
    "    grad = compute_grad(X[ind,:], y[ind], w)\n",
    "    v = beta * v + (1 - beta) * grad\n",
    "    c = mu * c + (1 - mu) * grad ** 2\n",
    "    w -= alpha / (c.sqrt() + eps) * v\n",
    "\n",
    "visualize(X, y, w, loss, n_iter)\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
